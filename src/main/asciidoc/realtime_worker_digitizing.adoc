= Оцифровка рабочего в режиме реального времени
:revealjs_theme: black
:revealjs_customtheme: theme.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images\realtime_worker_digitizing
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900

:!figure-caption:

image::logo.png[]

Алексей Коняев, akonyaev@croc.ru

== Цифровой рабочий

image::digital_worker.png[]

[.notes]
--
- Для чего предназначена система
- Какие целевые характеристики: кол-во объектов, кол-во сообщений в ед. времени
- Цель доклада - выяснить, как данные с носимого устройства становятся данными в UI и аналитич. панели
--

== Архитектура

image::architecture.jpg[]

[.notes]
--
- вкратце где какие модули, как они взаимодействуют друг с другом
--

== Kafka

Kafka, потому что:
- событийно-ориентированная архитектура
- потоковая обработка
- взаимодействие модулей внутри системы
- интеграция с внешними системами

[.notes]
--
- взаимодействие модулей - максимально независимо с возможностью легко добавлять новый функционал
--

== Адаптеры

[%step]
* Около 10 штук на данный момент
* Подключение к вендорской системе с помощью
** REST API
** Kafka
** MQTT
** WebSocket
** SignalR
* Подключение напрямую к оборудованию Java/С++ Library

(!) как правило, нельзя масшабировать, т.е. только один экземпляр

[.notes]
--
модули системы, которые выполняют роль переходного звена между внешники системами,
поставляющими данные от устройств, и всей остальной системой.
На входе имеют API внешней системы - на выходе
т.н. "сырые" события в Kafka в универсальном формате системы.
--

== "Сырые" события

* TagMovementEvent - перемещение
* TagInfoEvent - телеметрия
* TagAlertEvent - сигналы тревоги

(!) долго не храним - retention 1 сутки

== Транслятор. Задачи

картинка Kafka Streams + состояние

* Первоначальная обоработка "сырых" событий
** получение абсолютных координат
*** зональное позиционирование
** связывание метки с объектом
** вычисление дополнительных атрибутов:
*** остановка
*** потеря сигнала
*** вектор направления движения, скорость, ускорение*
* Работы с геозонами
** Вошел, вышел, находится внутри
** Подсчет кол-ва объектов в геозоне

[.notes]
--
- Kafka Streams Stateful-процессинг с применением кеширования справочных данных
--

== Транслятор. Архитектура

рисунок:
* на вход сырые события
* Kafka Streams - топология
* Hazelcast-кеш, который ходит в PostgreSql
* на выход - бизнес-события gen-1

(!) можно и нужно масштабировать!

[.notes]
--
1 траснятор обрабатывает события от ~50 объектов
--

== Бизнес-события gen-1

* ObjectMovement, ObjectInfo, ObjectAlert
* ZoneEntrance, ZoneObjects

(!) храним долго (1 месяц)
(!) UI потребляет эти события

== UI. Перемещение объектов

UI-backend

* подписывается на события
* транслирует события на клиента через веб-сокет
** фильтрация потока в зависимости от текущей выбранной геозоны
** кластеризация объектов

[.notes]
--
демо - как человечки ходят
--

== Complex Event Processing

* Обработка потока различных событий в реальном времени с целью выявления значимых событий, требующих
максимально быстрого реагирования

* Esper - Complex Event Processing by EsperTech
* Правила, которые выявляют внештатные ситуации, анализируя Gen-1-события
* Результат - сложные события, регистрируемые в журнале + нотификация
** неправильная ориентация каски
** пульс выше/ниже нормы
** вход в опасную зону
** вход постороннего в зону во время проведения работ
** удар/падение/неподвижность при отсутствии подтверждения, что все ОК

== Esper

* Event Processing Language (EPL)
* Контекст: [А -> Б и/или таймаут]
* Паттерн сложного события: context <контекст> SELECT <действие(поля...)> FROM <события, внешняя БД> WHERE <условия>

[.notes]
--
- EPL - SQL-standard language with extensions, offering SELECT, FROM, WHERE, GROUP BY, HAVING and ORDER BY clauses. Streams replace tables as the source of data with events replacing rows as the basic unit of data.
- контекст - партиционируется по заданым ключам
- Событие А - это может быть событие Х с заданными значениями атрибутов
--

== Почему Esper?

* Описывать правила декларативно
* Понятно не только разработчику
* Масштабируемый, Open source

[.notes]
--
Действительно зрелый продукт с багатым функционалом, мы его используем далеко не на всю его мощность
Альтернатива
- Flink-CEP, писать на java
- KSql, Kafka Streams - There is no out-of-the-box support. But it should be possible to use a CEP library (like Esper) via Processor API. – Matthias J. Sax Dec 8 '18
--

== Журнал событий

демо срабатывания предупреждения при внештатной ситуации - вход постороннего в зону работ по НД

== Аналитика

* подготовка данных
* загрузка данных в аналитическую БД
* обработка запросов

== Модули подготовки данных для аналитики

Процессоры на базе Kafka Streams
* фильтрация
* денормализация / обогащение
* форматирование

[.notes]
--
- фильтрация для треков - пропускать событие, если объект переместился незначительно
- фильтрация события нахождения внутри зоны
- форматирование - выпремление json-а
--

== Clickhouse

- загрузка событий из кафки
- использование внешних справочников (данные из PostgreSql)
- данные храним постоянно

[.notes]
--
аналитическая БД, в которой накапливаем данные
--

== Почему Clickhouse?

* удобная интеграция с Kafka
* партиционирование данных по времени событий и ИД объекта
* дополнительная обработка при записи данных
* богатые аналитический функции
* быстро работает для наших сценариев

[.notes]
--
- при определении MATERIALIZED VIEW в селекте из стрима выполняем доп. обработку данных
- функции: квантиль используем при формировании heatmap-а
- работа с массами (строки завернуть в массив, получить пересечение, и обратно развернуть в строки, ARRAY JOIN)
- наши сценарии: формирование аналитики за период
--

== Модуль Reports

Обрабатывает аналитические запросов
* запросы приходят из Kafka
* тип запроса -> генератор -> динамический sql-запрос в Clickhouse
* форматирование результата (данные, Excel, Pdf)
* сохранение отчетов в файловое хранилище
* отправка ответа на запрос через Kafka

== Зачем отдельный модуль Reports?

* часть работы выполняется в Java - переваривание результата sql-запроса
* сокрытие работы с Clickhouse за интерфейсом типизированных запросов
* возможность масштабировать

== Аналитическая панель

* Панель виджитов
** своя для каждого пользователя
** виджет периодически отправляет запрос в Reports

== Отчеты

* Запрос формирования нового отчета
* Журнал отчетов

== Тепловые карты

* картинка

== Маршруты

* картинка

== История событий

* воспроизведение истории событий (перемещение, алерты, нотификации).

[.notes]
--
Специализированный Kafka Consumer, который вычитыва события из топиков
за заданный период в прошлом с сохранением темпа их поступления.
--
