= Оцифровка рабочего в режиме реального времени
:revealjs_theme: black
:revealjs_customtheme: theme.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images\realtime_worker_digitizing
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900

:!figure-caption:

Алексей Коняев,
ведущий разработчик КРОК,
akonyaev@croc.ru

== Цифровой рабочий
[cols="30a,70a",frame=none,grid=none]
|===
.^|
* Позиционирование внутри и снаружи помещений
* Выявление внештатных ситуаций
* RealTime аналитика
.^|image::digital_worker.png[]
|===

//[.notes]
//--
//Бизнес-польза от системы
//
//* быстрое реагирование на внештат. ситуации
//* аналитика с целью оптимизации производств. процесса
//--

== Поток обработки событий
image::tag_to_ui.jpg[]

//[.notes]
//--
// Как данные с носимого устройства превращаются в нотификации в UI
//--

== Архитектура
image::architecture.jpg[width=50%]

//[.notes]
//--
//- вкратце где какие модули, как они взаимодействуют друг с другом
//--

== Kafka
* Событийно-ориентированная архитектура
* Потоковая обработка
* Взаимодействие модулей внутри системы
* Интеграция с внешними системами

[.notes]
--
- СОА выбрали потому, что на входе у нас события и потом по мере их обработки
    событий рождается еще больше
- потоковая оброаботка - нужно обрабатывать события на лету, причем
    логика обработки растет как снежный ком. Но при этом, нужно было сохранить
    независимость кусков логики друг от друга, иметь возможность в будущем
    добавлять новые кейсы обработки событий
- взаимодействие модулей и интеграция - это нужно было в любом случае делать,
    и кафка удовлетворяет все наши потребности в этом:
    - единая точка определения форматов (на каждое событие есть свой класс + json-сериализация)
    - балансировка благодаря партиционированию топиков
    - асинхронность (не везде нужно, но там где нельзя "зависать", оч. полезно)
--

== Адаптер
* Около 10 штук на данный момент
* Подключение к вендорским системам с помощью
** REST API
** Kafka
** MQTT
** WebSocket
** SignalR
* Подключение напрямую к оборудованию
* Сложно масшабировать => должны быть производительными

[.notes]
--
- "переходники" между внешники системами и нашей
- нужна макс. производительность, поэтому ничего лишнего не делаем
- на входе API внешней системы - на выходе т.н. "сырые" события во внутреннем формате
--

== "Сырые" события
[cols="50a,50a",frame=none]
|===
.^|
* Перемещение - TagMovement
* Телеметрия - TagInfo
* Тревога - TagAlert
.^|
* Внутренний универсальный формат
* до 5 событий в секунда от одной метки
* Долго не храним (1 сутки)
|===

== Поток событий

image::flow_1.jpg[width=75%]

== Транслятор
[cols="70a,30a",frame=none]
|===
.^|
* Обоработка "сырых" событий:
** вычисление абсолютных координат
** зональное позиционирование
** связывание метки с объектом
** определение остановки объекта
** обнаружение потери сигнала
* Работы с геозонами:
** Вошел, вышел, находится внутри
** Подсчет объектов в геозоне
.^|image::topology.jpg[]
|===

//[.notes]
//--
//- Kafka Streams Stateful-процессинг с применением кеширования справочных данных
//- в будущем: вектор направления движения, скорость, ускорение
//--

== Транслятор. Архитектура
[cols="70a,30a",frame=none]
|===
.^|
* Процессоры
* Stateful-обработка + пунктуатор
* Сложные вычисления
* Кеш для доступа к данным в БД
* Можно и нужно масштабировать!
.^|image::translator_architecture.jpg[]
|===

//[.notes]
//--
//* на вход сырые события
//* Kafka Streams - топология
//* Hazelcast-кеш, который ходит в PostgreSql - нужен поточу, что важно бысто выполнять обработку
//  внутри стрима, а ходить постоянно в БД долго
//* на выход - бизнес-события gen-1
//1 траснятор обрабатывает события от ~50 объектов
//--

== Идеология

[cols="55a,5a,40a",frame=none]
|===
.^|
* KafkaConsumer -> подписка на события по типу
* KafkaProducer -> сам определяет топик
* Автоматическое построение топологии
.^|
.^|
Один топик -- один тип события
|===

//[.notes]
//--
//- на уровн кода работаем только с событиями
//- при определении процессора указываем тип входного события и выходного
//- автоматически находим все процессоры и связываем в граф, стыкуя их по типу событий
//- это не так гибко, как Kafka Streams API, но зато значительно
//  упрощает добавление нового процессора
//--

== Бизнес-события
* На одно "сырое" - 5 бизнес-событий
* Передаются в UI и другим потребителям
* Храним долго (1 месяц)

== Поток событий

image::flow_2.jpg[width=75%]

== Перемещение объектов
* Подписывается на бизнес-события
* Передает события на клиента через веб-сокет
* Фильтрация и редукция потока событий
* Кластеризация объектов

// Фильтрация потока событийв зависимости от текущей выбранной геозоны
// кластеризация на клиенте

== Перемещение объектов

Демо

== Complex Event Processing
Обработка потока различных событий в реальном времени с целью выявления значимых событий,
требующих максимально быстрого реагирования.

== CEP-процессор
* Правила, которые выявляют внештатные ситуации
** вход в опасную зону
** неправильная ориентация каски
** пульс выше/ниже нормы
** удар/падение/неподвижность
* Сложные события регистрируются в журнале
* Отправляются нотификации

== Esper
* 2006 by EsperTech Inc.
* Open Source, Java
* Есть интеграция с Kafka
* Event Processing Language
** Расширение SQL
** Компилируется в байткод
* Быстрый
* Горизонтально масштабируемый

// интеграцию с Kafka - пришлось немного допилить, чтобы явно указывать топики,
// из которых читать и топики, в которые писать

== Esper. EPL. Схемы
* События из Kafka
** топик -> таблица
** событие -> строка в таблице
* Схема - runtime-таблицы
[source,sql]
----
create schema MySchema(objectId string, coordinates Coordinates);

insert into MySchema
select objectId, coordinates
from ObjectMoveEvent;
----

== Esper. EPL. Окна
* Последние N событий
[source,sql]
----
select sum(amount) from Event#length(N)
----
* Скользящее (sliding)
[source,sql]
----
select name, avg(amount) from Event#time(T) group by name
----
* Прыгающее (hopping)
[source,sql]
----
select * from Event#time_batch(T) where amount > 100
----

// sliding
// hopping / tumbling

== Esper. EPL. Контекст
* Партиционирование по полям событий
* Условие создания и удаления
[source,sql]
----
create context Ctx
partition by objectId FROM ZoneEntranceEvent
initiated by ZoneEntranceEvent(entranceType = ENTERED)
terminated by pattern[ZoneEntranceEvent(entranceType = LEFT) OR timer:interval(60 sec)];
----

== Esper. EPL. Выражения
[source,sql]
----
@KafkaOutputTopic('notification')
context Ctx
select transpose(createNotification(e.objectId, ...))
from ZoneEntranceEvent#firstunique(zoneId) e
where e.isDangerous() = true

insert into MySchema
select e.objectId, ...
from ZoneEntranceEvent#lastevent e
----

//[.notes]
//--
// time(T) - sliding-window или скользящее окно - события за последние T секунд
// time_batch(T) - tumbling/Hopping window или шагающее/прыгающее окно - события за последнюю пачку из Т секунд
//
// партиция/контекст - таблица, в которой накапливаются события для анализа
//
// чтобы партиционировать, нужно объявить контект
// аналог прыгающего окна: `create context Ctx start @now end after 5 sec`

// @KafkaOutputTopic - наша аннотация
// transpose - встроенная функция, которая принимает java-объект и отправляет его в выходной поток
// createNotification - наш метод, который задекларирован при инициализации Esper-а
//--

== Esper. Альтернативы
* Kafka Streams - низкоуровневый API на Java
* KSqlDB - все-таки это ESP, а не CEP
* FlinkCEP - мало возможностей

//[.notes]
//--
//Действительно зрелый продукт с багатым функционалом, мы его используем далеко не на всю его мощность
//Альтернатива
//- KSql, Kafka Streams - There is no out-of-the-box support.
//    But it should be possible to use a CEP library (like Esper) via Processor API. – Matthias J. Sax Dec 8 '18
//  Все таки кафка - это ESP (Event Stream Processing), который является менее сложным, чем CEP.
//  Суть CEP в том, что нужно находить паттерны среди потока разных событий
//- Flink-CEP, писать на java, нет окон, например
//--

== Поток событий

image::flow_3.jpg[width=75%]

== Журнал событий и нотификации

Демо
// срабатывания предупреждения при внештатной ситуации - вход постороннего в зону работ по НД

== Аналитика
* Подготовка данных
* Загрузка данных в аналитическую БД
* Обработка запросов

TODO: картинка!

== Модули подготовки данных для аналитики
Kafka Streams процессоры

* Фильтрация
* Денормализация / обогащение
* Форматирование

//[.notes]
//--
//- фильтрация для треков - пропускать событие, если объект переместился незначительно
//- фильтрация события нахождения внутри зоны
//- форматирование - выпремление json-а
//--

== Clickhouse
* Загрузка событий из Kafka
* Использование внешних справочников из PostgreSql
* Данные храним постоянно

//[.notes]
//--
//аналитическая БД, в которой накапливаем данные
//--

== Почему Clickhouse?
* Удобная интеграция с Kafka
* Партиционирование данных по времени событий и ИД объекта
* Дополнительная обработка при записи данных
* Богатый набор аналитических функции
* Быстро работает для наших сценариев

//[.notes]
//--
//- при определении MATERIALIZED VIEW в селекте из стрима выполняем доп. обработку данных
//- функции: квантиль используем при формировании heatmap-а
//- работа с массами (строки завернуть в массив, получить пересечение, и обратно развернуть в строки, ARRAY JOIN)
//- наши сценарии: формирование аналитики за период
//--

== Модуль Reports
* Запросы приходят из Kafka
* Тип запроса -> генератор -> динамический SQL-запрос в Clickhouse
* Форматирование результата (данные, Excel, Pdf)
* Сохранение отчетов в файловое хранилище
* Отправка ответа на запрос в Kafka

//[.notes]
//--
// Обрабатывает аналитические запросов
//--

== Зачем отдельный модуль Reports?
* Часть работы выполняется в Java
* Сокрытие работы с Clickhouse за интерфейсом типизированных запросов
* Возможность масштабировать

== Аналитическая панель
* Панель виджитов
** своя для каждого пользователя
** виджет периодически отправляет запрос в Reports

== Отчеты
* Запрос формирования нового отчета
* Журнал отчетов

== Тепловые карты
(!) картинка

== Маршруты
(!) картинка

== История событий
* Вычитывание событий из Kafka
* Сохранение темпа воспроизведения
* Плюсы:
** не нужно отдельное хранилище
** прозрачно для потребителя
** новые типы событий автоматически доступны для истории
* Минусы:
** период хранения истории ограничен
** проблемы с получением состояния в начальный момент времени

//[.notes]
//--
//Специализированный Kafka Consumer, который вычитыва события из топиков
//за заданный период в прошлом с сохранением темпа их поступления.
//--

== Выводы
[%step]
* Kafka - удачный выбор для EDA
* При потоковой обработке помогает кеш
* Clickhouse - тоже удачное решение для накопления аналитических данных

// EDA - Event-driven architecture