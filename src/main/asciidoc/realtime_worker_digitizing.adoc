= Оцифровка рабочего в режиме реального времени
:revealjs_theme: black
:revealjs_customtheme: theme.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images\realtime_worker_digitizing
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900

:!figure-caption:

image::logo.jpg[]

Алексей Коняев
{nbsp} +
ведущий разработчик в КРОК

//[%notitle]
== Цифровой рабочий
image::digital_worker.png[canvas,size=contain]

[.notes]
--
    !! не говорить "здесь вот это, а на самом деле это..."
говорить: это офис крок... не надо долго рассказывать,
    а сразу привести один интересный кейс про взрыв.
    а такая система может это предотвратить, если все носят метки и есть разметка территории.
    убрать маркетинговую составляющую - больше говорить про технологии.
--

== Поток обработки событий
image::tag_to_ui.jpg[]

[.notes]
--
 !! говорю за счет чего это достигается...

 Рассказажу, как данные с носимых устройств превращаются в нотификации в UI.
И как вообще может выглядеть архитектура системы, которая должна справляться
с большим потоком событий, а также как мы сделали выявл. внештат. ситуация и реалтайм аналитику
--

== Архитектура
image::architecture_0.jpg[width=58%]

[.notes]
--
 Давайте посмотрим на архитектуру высокоуровнево...
--

== Архитектура
image::architecture_1.jpg[width=58%]

== Архитектура
image::architecture_2.jpg[width=58%]

== Архитектура
image::architecture_3.jpg[width=58%]

== Архитектура
image::architecture_4.jpg[width=58%]

== Архитектура
image::architecture_5.jpg[width=58%]

== Архитектура
image::architecture_6.jpg[width=58%]

[.notes]
--
 !! упомянуть про СОА, а в остальном меньше говорить про Кафку - просто что утилизируем ее возможности.

 !
* Событийно-ориентированная архитектура
* Потоковая обработка на Kafka Streams
* Независимое чтение событий разными потребителями
* Возможность прочитать события еще раз
* Взаимодействие модулей внутри системы
* Интеграция с внешними системами
* Масштабирование обработки
 !
ну на самом деле, изначально мы думали выбрать Rebbit, т.к. это было более популярное
решение, которое мы применяли уже в других проектах.
Но потом, когда я начал больше изучать скажем так теорию, то пришел к выводу, что
для СОА лучше ну иои не меньше подходит кафка, но еще у нее есть потоковая обработка,
которая нам как раз нужна была.
А вот дальше мы открыли для себя другие ее полезные качества, как то:
- возможность читать события повторно
- возможность использовать ее практически как шину внутри системы и для взаимодействия с внеш. системами
- ну и конечно возможность масштабирования обработки благодаря партиционированию топиков
--

== Толя Грачкин

[cols="50a,50a",frame=none]
|===
.^|
* Местоположение объектов
* Нотификация о внештатных ситуациях
* RealTime аналитика
* Воспроизведение истории
.^|image::tolya_1.jpg[width=100%, caption="", title="\"Неподдающиеся\", 1959 г"]
|===

[.notes]
--
 ! Толя - это инженер ЦОД, который обслуживает газотурбинные генераторы (на случай отключения эл-ва).
    Он хороший парень, но есть проблемы с дисциплиной, а т.к. ЦОД - это объект повышенной опасности (эл-во, гаовая система пажаротушения и пр.),
    то важно, чтобы сотрудники ЦОД четко следовали должн. инструкциям.
    И если раньше можно было приставить к Толе комсомолку Надю, то в наше время цифровизации мы ему наденем каску с устр-вом позиционирования.
--

== Толя Грачкин

[cols="50a,50a",frame=none]
|===
.^|
* Местоположение объектов
* Нотификация о внештатных ситуациях
* RealTime аналитика
* Воспроизведение истории
.^|image::tolya_2.jpg[width=100%, caption="", title="\"Неподдающиеся\", 1959 г"]
|===

== Поток событий. Местоположение

image::flow_1.jpg[width=75%]

== Адаптер
* Подключение к вендорским системам с помощью
** REST API
** Kafka
** MQTT
** WebSocket
** SignalR
* Подключение напрямую к оборудованию
* Сложно масштабировать => *нужна высокая производительность*

[.notes]
--
 ! адаптеры нужны для реализации разных протоколов взаимодействия с вендорскими системами.
    где то оборудование мы подключаем напрямую.
--

== "Сырые" события

* Виды событий метки
** Перемещение -- TagMovement
** Телеметрия -- TagInfo
** Тревога -- TagAlert
* Внутренний универсальный формат
* до 5 событий в секунда от одной метки
* Долго не храним (1 сутки)

[.notes]
--
 ! Эти события имеет смысл хранить только на время потенциального останова системы из-за сбоя,
т.к. они в нормальной ситуации сразу же обрабатываются, после чего их можно выкинуть.
 ! не говорить про актуальность событий по прошествие времени.
--

== Поток событий. Местоположение

image::flow_2.jpg[width=75%]

== Транслятор

[cols="50a,50a",frame=none]
|===
.^|
* Связывание метки с объектом
** Вычисление географических координат
** Определение остановки объекта
** Обнаружение потери сигнала
* Геозоны
** Вход/выход
** Подсчет объектов в геозоне
.^|image::tolya-3.jpg[width=100%, caption="", title="\"Неподдающиеся\", 1959 г"]
|===

[.notes]
--
 !
* Толя может ходить как на улице, и тогда мы получаем GPS-координаты,
так и внутри помещений, где это могут быть координаты на коорд. плоскости внутри вендор. системы.
поэтому мы приводим все координаты к единому виду, а именно в широту и долготу.
* если Толя остановится, то его координаты мало будут изменяться по сравнению с предыдущими
* если забудет зарядить метку, то сигнал может пропасть

--

== Транслятор. Процессоры

[cols="50a,50a",frame=none]
|===
.^|
* Kafka Streams Processors API
* Stateful-обработка
* Punctuator (шедулер)
* Один тип события -- один топик
.^|
image::topology.jpg[]
|===

[.notes]
--
 !
* Почему Kafka Streams?
** изначально выбрав кафку, знали что в ней есть механизм потоковой обработки.
** Есть возможность использовать состояние
** Есть пунктуаторы - позволяют периодически проверять все состояния
** Из одного топика могут параллельно и независимо получать события разные консюмеры
* Сделали обертку над Kafka Streams API, чтобы можно было
на уровне кода оперировать типом события на вход и на выход,
что значительно упрощает добавление нового процессора
--

== Транслятор. Низкая производительность

[%step]
* Проблема: Долгая обработка события
* Решение: Кэширование доступа к БД

[.notes]
--
 ! пока Толя был один - все было хорошо, но когда мы попробовали отслеживать больше 10 человек, то начались проблемы.
    Начали искать узкое место и поняли, что тормозит обращение к БД.
    А т.к. данные в БД не меняются, то можно их кешировать.
--

== Транслятор. Кэширование
[cols="70a,30a",frame=none]
|===
.^|
*Hazelcast*

* Просто библиотека
* Распределенный кэш
* Проверенное Open Source решение

.^|image::processor.jpg[]
|===

[.notes]
--
 ! начать с конца - перечислить и "это все что нам нужно", не доказывать почему его выбрали.
 !! если говорю Open Source - не говорить "бесплатно".
 .
* просто библиотека - не нужно поднимать отдельного зверя, как например в случае с Redis
* распределенный кеш - распределенная хеш-таблица по всем узлам кластера
* много кто использует - Тинькофф, Яндекс, нам тоже хотелось попробовать
--

== Транслятор. Производительность

* 1 экземпляр
** 2 CPU + 2 Gb
** Amazon EC2 t4g.micro
* Пропускная способность
** событий в секунду
*** входящих -- 500
*** исходящих -- 1500
** 100 до 10 тысяч меток
* Объем на диске в Kafka:
** входящие события -- 36 Gb/day
** исходящие события -- 1 Tb/month

[.notes]
--
 ! производит. стала - ОК, но теперь увидили, что много места требуется на харде,
    и это даже с включенной компрессией в кафке.
    Но на самом деле это не проблема, т.к. какие то данные долго не храним, а другие - ну да, храним,
    но это уже ничего не поделаешь.
 .
 t4g instances - это general purpose
--

== Бизнес-события

[cols="50a,50a",frame=none]
|===
.^|
* Имеют ценность для бизнеса
* На одно "сырое" -- несколько бизнес-событий
* Передаются в UI и другим потребителям
* Храним долго (1 месяц)
.^|image::tolya-4.jpg[width=100%, caption="", title="\"Неподдающиеся\", 1959 г"]
|===

[.notes]
--
 !
* ценность - какие то меткири, например, что Толя вообще надел каску, а не оставил ее в раздевалке
--

== Поток событий. Местоположение

image::flow_3.jpg[width=75%]

== Перемещение объектов
* UI подписывается на бизнес-события
* Передает события на клиента через веб-сокет
* Фильтрация и редукция потока событий
* Кластеризация объектов

[.notes]
--
 !
* Не предполагается High-load-а для работы с UI, но в то же время гнать на клиента все-все события нельзя,
т.к. их оч. много.
* Фильтрация потока событий в зависимости от текущей выбранной геозоны
** кластеризация на клиенте
--

== Демо. Перемещение объектов
video::demo-1.mp4[]

[.notes]
--
 ! ответы на ВОПРОС:
Какие технологии кэширования вы используете при потоковой обработке?
- Hazelcast
- Apache Ignite
- Своя реализация (какая?)
- У нас и так не тормозит:)
--

== Поток событий. Внештатные ситуации

image::flow_4.jpg[width=75%]

== Complex Event Processing
[cols="40a,60a",frame=none]
|===
.^|
image::david_luckham.jpg[width=50%]
David Luckham,
{nbsp}

Stanford University
.^|
Обработка потока различных событий в реальном времени
с целью выявления паттернов значимых событий
|===

[.notes]
--
 ! CEP - это подход или парадигма, разработанная в 1990-х годах
    доктором Дэвидом Лакхэмом из Стэнфордского университета.
 ! задача CEP - выявить определенные шаблоны в потоке низкоуровневых событий, при этом зачастую
комбинируя данные из различных источников, чтобы составить общую картину о мире.
--

== ESP vs CEP
[cols="47a,6a,47a",frame=none]
|===
|
Event Stream Processing

* Упорядоченные события одного типа
* Фильтрация, трансформация
* Агрегация, группировка
|
|
Complex Event Processing

* Различные не обязательно упорядоченные события
* Анализ внутри временного окна
* Причинно-следственная связь
|===
{nbsp}

"ESP tools trend towards including a full set of CEP capabilities"

(c) David Luckham and Roy Schulte, 2020

[.notes]
--
 ! CEP - развивающаяся парадигма, разработанная в 1990-х годах доктором Дэвидом Лакхэмом из Стэнфордского университета.
 ! Пример ESP - следить на ценой акций и продавать при достижении определенного порога
 ! CEP - более сложная штука чем ESP
--

== CEP-процессор
* Правила, которые выявляют внештатные ситуации
** вход в опасную зону
** неправильная ориентация каски
** пульс выше/ниже нормы
** удар/падение/неподвижность
* Сложные события регистрируются в журнале
* Отправляются нотификации

== Esper
* 2006 by EsperTech Inc.
* Open Source, Java
* Есть интеграция с Kafka
* Event Processing Language
** Расширение SQL
** Компилируется в байткод
* Горизонтально масштабируемый

[.notes]
--
 ! говорить локонично
--

== Esper. Альтернативы
* FlinkCEP - мало возможностей
* Spark Streaming - аналог Kafka Streams
* TIBCO Streaming, IBM Streams, Amazon Kinesis
* ...

[.notes]
--
 ! есть большие платные системы, можно было бы и на них, но для наших задач мы выбрали Esper
--

== Esper? Может все таки Kafka Streams / KSqlDB!
image::is_ksqldb_cep.jpg[width=80%]

[.notes]
--
 !
* Kafka Streams - низкоуровневый API на Java
* KSqlDB - все-таки это ESP, а не CEP
* я как программист, все таки предпочитаю java,
    но есть требование бизнеса, чтобы аналитики понимали.
* это как при первом переходе на NoSql после опыта только с реляционками
--

== Esper. Почему выбрали
[%step]
* Программирование на более высоком уровне
* Понятен не только разработчикам
* Мощный инструмент
* Можно быстро реализовать сложные вещи

[.notes]
--
 ! самая важная часть - про быстро реализовать сложные вещи
--

== CEP. Пример
{nbsp}

[cols="20a,80a",frame=none]
|===
.<| Задача:
.<| Не оставлять включенное оборудование без присмотра
.<| Дано:
.<|
* Событие "Изменение кол-во людей в геозоне"
* Событие "Изменение состояния оборудования"
* Макс. время без присмотра - 1 час
|===

[.notes]
--
 ! расуждаю о том, как бы я это делал на Kafka Streams
--

== Демо. Реализация правила
{nbsp}

https://notebook.esperonline.net/#[Esper Notebook]

video::esper_notebook.mp4[]

== Поток событий. Внештатные ситуации

image::flow_5.jpg[width=75%]

== Демо. Нотификации

video::demo-2.mp4[]

[.notes]
--
 ! ответы на ВОПРОС:
    Какое CEP-решение вы применяете?
    - Делаем все на Kafka Streams / KSqlDB
    - Esper
    - Flink
    - Другое решение (какое?)
    - У нас нет задач Complex Event Processing-а
--

== Поток событий. Аналитика
image::flow_6.jpg[width=75%]

[.notes]
--
 ! оперативные данные - хорошо, но нам нужно видеть картину в целом по прошествии
    времени, поэтому - аналитика
--

== Подготовка данных
[cols="50a,50a",frame=none]
|===
.^|
На Kafka Streams процессорах:

* Фильтрация
* Денормализация / обогащение
* Форматирование
.^|image::tolya-5.jpg[width=100%, caption="", title="\"Неподдающиеся\", 1959 г"]
|===

[.notes]
--
 !
* фильтрация - есть отчет "Маршрут передвижения" и если Толя долго стоит на одном месте,
    но нет смысла сохранять для этого отчета все события с примерно одинаковыми координатами
* обогащение - максимально достать все необходимые для отчета данные заранее, а не во время формирования отчета
--

== Поток событий. Аналитика
image::flow_7.jpg[width=75%]

== Аналитическая БД. Требования

* Хранить очень много данных
* Быстро выполнять запросы с условием С -- ПО

== ClickHouse
* Аналитическая БД от Yandex
* Колоночная, масштабируемая, отказоустойчивая
* Встроенное сжатие данных
* Подходит для Time-series данных
* Хороший вариант использования - читать данные "пачками"

[.notes]
--
 !
* Time-series - упорядочены по времени
* пояснить что значит "читать пачками" и это естесственно для аналитических запросов.
--

== Clickhouse. Как используем
* Загрузка данных из Kafka
* Дополнительная обработка при загрузке данных
* Подключение справочников из PostgreSql
* "Широкие" таблицы с партиционированием по времени события и Id
* Аналитические функции

[.notes]
--
 !
* встроенный движок загрузки данных из Kafka
* при определении MATERIALIZED VIEW в селекте из стрима выполняем доп. обработку данных
* подключение справочников в виде словарей, которые КХ сам периодически обновляет
аналитическая БД, в которой накапливаем данные
* функции: квантиль используем при формировании heatmap-а
* работа с массами (строки завернуть в массив, получить пересечение, и обратно развернуть в строки, ARRAY JOIN)
--

== Поток событий. Аналитика
image::flow_8.jpg[width=75%]

== Формирование отчетов
* Запросы приходят из Kafka
* Тип запроса -> генератор -> динамический SQL-запрос
* Форматирование результата (данные, Excel, Pdf)
* Сохранение отчетов в файловое хранилище
* Отправка ответа на запрос в Kafka

== Асинхронные запросы через Kafka

* Не ждем, пока запрос выполняется
* Заказать отчет может кто угодно
* Масштабирование
* Нужно сопоставлять ответ с запросом

[.notes]
--
 !
* обычно запрос выполняется быстро, но если задать большой диапазон дат, например, то может и долго.
** кроме того, как обработки приходится делать руками на Java
* масштабируемся и балансируемся благодаря партиционированию топиков в кафке
--

== Демо. Аналитика

video::demo-3.mp4[]

[.notes]
--
 ! ответ на ВОПРОС
    Какую БД для аналитики используете?
    - ClickHouse
    - InfluxDB
    - Microsoft SQL Server Analysis Services (OLAP)
    - NoSQL Database
    - SQL Database
--

== Поток событий. История

image::flow_9.jpg[width=75%]

== История событий
* Вычитывание событий из Kafka за период в прошлом
* Сохранение темпа воспроизведения
* Плюсы
** не нужно отдельное хранилище
** прозрачно для потребителя
** новые типы событий автоматически доступны для истории
* Минусы
** период хранения истории ограничен
** проблемы с получением состояния в начальный момент времени

[.notes]
--
 !
Специализированный Kafka Consumer, который вычитыва события из топиков
за заданный период в прошлом с сохранением темпа их поступления.
--

== Демо. История

video::demo-4.mp4[]

[.notes]
--
 ! тут на демо мы вдруг обнаружили, что Толя на балкон ходит курить не один,
    а с товарищем
--

== Выводы
[%step]
* Kafka - удачный выбор для Event Driven Architecture
* При потоковой обработке помогает кэш
* Esper - хорошее решение для CEP
* Clickhouse - то, что нужно для аналитики по Time-series данным
* Kafka - удобно применять для воспроизведения истории

[.notes]
--
 !
* вообще на Kafka можно сделать всю интеграцию и балансировку, как внутренюю, так и внешнюю
* кеш - потому что нелья тормозить поток. обработку
* Esper - много всего умеет и в принципе, довольно удобное решение,
но нужно поднатаскаться и изучить возможности
* Clickhouse - партиционирование, масштабируемость, заточен под аналитику
--

== Полезные ссылки про CEP

* Confluent blog: https://www.confluent.io/learn/complex-event-processing[What is CEP?]
* Complex events: https://complexevents.com/2020/06/17/the-future-of-event-stream-analytics-and-cep[The Future of Event Stream Analytics and CEP]
* Esper: https://www.espertech.com/esper
* Esper Notebook: https://notebook.esperonline.net

== Спасибо!

image::akonyaev.jpg[width=15%]

*Алексей Коняев*

* icon:envelope[size=lg] akonyaev@croc.ru
* icon:github[size=lg] https://github.com/a-konyaev[a-konyaev]
