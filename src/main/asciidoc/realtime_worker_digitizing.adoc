= Оцифровка рабочего в режиме реального времени
:revealjs_theme: black
:revealjs_customtheme: theme.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images\realtime_worker_digitizing
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900

:!figure-caption:

Алексей Коняев,
ведущий разработчик КРОК,
akonyaev@croc.ru

//[cols="30a,70a",frame=none]
//|===
//.^|
//.^|image::logo.jpg[]
//|===

== Цифровой рабочий
[cols="30a,70a",frame=none,grid=none]
|===
.^|
[%step]
* Позиционирование внутри и снаружи помещений
* Выявление внештатных ситуаций
* Аналитика
.^|image::digital_worker.png[]
|===

//[.notes]
//--
//Бизнес-польза от системы
//
//* быстрое реагирование на внештат. ситуации
//* аналитика с целью оптимизации производств. процесса
//--

== Процесс обработки данных
image::helmet-to-ui.jpg[]


//[.notes]
//--
//Цель доклада - выяснить, как данные с носимого устройства
//становятся данными в UI и аналитич. панели
//--

== Архитектура
image::architecture.jpg[]

//[.notes]
//--
//- вкратце где какие модули, как они взаимодействуют друг с другом
//--

== Kafka
[%step]
* Событийно-ориентированная архитектура
* Потоковая обработка
* Взаимодействие модулей внутри системы
* Интеграция с внешними системами

//[.notes]
//--
//- Почему Кафка - перечисляю
//- взаимодействие модулей - максимально независимо с возможностью легко добавлять новый функционал
//--

== Адаптеры
[%step]
* Около 10 штук на данный момент
* Подключение к вендорской системе с помощью
** REST API
** Kafka
** MQTT
** WebSocket
** SignalR
* Подключение напрямую к оборудованию Java/С++ Library
* Нельзя масшабировать - только один экземпляр!

//[.notes]
//--
//модули системы, которые выполняют роль переходного звена между внешники системами,
//поставляющими данные от устройств, и всей остальной системой.
//На входе имеют API внешней системы - на выходе
//т.н. "сырые" события в Kafka в универсальном формате системы.
//--

== "Сырые" события
[cols="50a,50a",frame=none]
|===
.^|
* TagMovementEvent - перемещение
* TagInfoEvent - телеметрия
* TagAlertEvent - сигналы тревоги
.^|
[%step]
* Внутренний универсальный формат
* Долго не храним (1 сутки)
|===

== Транслятор
[cols="70a,30a",frame=none]
|===
.^|
[%step]
* Первоначальная обоработка "сырых" событий:
** вычисление абсолютных координат
** зональное позиционирование
** связывание метки с объектом
** остановка объета
** потеря сигнала
* Работы с геозонами:
** Вошел, вышел, находится внутри
** Подсчет кол-ва объектов в геозоне
.^|image::topology.jpg[]
|===

//[.notes]
//--
//- Kafka Streams Stateful-процессинг с применением кеширования справочных данных
//- в будущем: вектор направления движения, скорость, ускорение
//--

== Транслятор. Архитектура
[cols="70a,30a",frame=none]
|===
.^|
[%step]
* Процессоры
* Stateful-обработка
* Кеш для работы с БД
* Можно и нужно масштабировать!
.^|image::kafka-streams-with-store.jpg[]
|===

//[.notes]
//--
//* на вход сырые события
//* Kafka Streams - топология
//* Hazelcast-кеш, который ходит в PostgreSql
//* на выход - бизнес-события gen-1
//1 траснятор обрабатывает события от ~50 объектов
//--

== Бизнес-события
[cols="50a,50a",frame=none]
|===
.^|
[%step]
* События объектов
** ObjectMovement
** ObjectInfo
** ObjectAlert
* События геозон
** ZoneEntrance
** ZoneObjects
.^|
[%step]
* Храним долго (1 месяц)
* UI потребляет эти события
|===

== UI. Перемещение объектов
[%step]
* Подписывается на события
* Передает события на клиента через веб-сокет
** Фильтрация потока в зависимости от текущей выбранной геозоны
** Кластеризация объектов

== UI. Перемещение объектов
Демо

== Complex Event Processing
Обработка потока различных событий в реальном времени с целью выявления значимых событий,
требующих максимально быстрого реагирования

== CEP-процессор
[%step]
* Правила, которые выявляют внештатные ситуации, анализируя бизнес-события
* Результат - сложные события, регистрируемые в журнале + нотификация
** неправильная ориентация каски
** пульс выше/ниже нормы
** вход в опасную зону
** вход постороннего в зону во время проведения работ
** удар/падение/неподвижность при отсутствии подтверждения, что все ОК

== Esper
[%step]
* Esper by EsperTech
* Event Processing Language (EPL)
* Контекст: [А -> Б и/или таймаут]
* Паттерн сложного события: context <контекст> SELECT <действие(поля...)> FROM <события, внешняя БД> WHERE <условия>

//[.notes]
//--
//- EPL - SQL-standard language with extensions, offering SELECT, FROM, WHERE, GROUP BY, HAVING and ORDER BY clauses. Streams replace tables as the source of data with events replacing rows as the basic unit of data.
//- контекст - партиционируется по заданым ключам
//- Событие А - это может быть событие Х с заданными значениями атрибутов
//--

== Почему Esper?
[%step]
* Описывать правила декларативно
* Понятно не только разработчику
* Масштабируемый
* Open source

//[.notes]
//--
//Действительно зрелый продукт с багатым функционалом, мы его используем далеко не на всю его мощность
//Альтернатива
//- Flink-CEP, писать на java
//- KSql, Kafka Streams - There is no out-of-the-box support. But it should be possible to use a CEP library (like Esper) via Processor API. – Matthias J. Sax Dec 8 '18
//--

== Журнал событий
демо срабатывания предупреждения при внештатной ситуации - вход постороннего в зону работ по НД

== Аналитика
[%step]
* Подготовка данных
* Загрузка данных в аналитическую БД
* Обработка запросов

== Модули подготовки данных для аналитики
[%step]
Kafka Streams процессоры
* Фильтрация
* Денормализация / обогащение
* Форматирование

//[.notes]
//--
//- фильтрация для треков - пропускать событие, если объект переместился незначительно
//- фильтрация события нахождения внутри зоны
//- форматирование - выпремление json-а
//--

== Clickhouse
[%step]
* Загрузка событий из Kafka
* Использование внешних справочников из PostgreSql
* Данные храним постоянно

//[.notes]
//--
//аналитическая БД, в которой накапливаем данные
//--

== Почему Clickhouse?
[%step]
* Удобная интеграция с Kafka
* Партиционирование данных по времени событий и ИД объекта
* Дополнительная обработка при записи данных
* Богатый набор аналитических функции
* Быстро работает для наших сценариев

//[.notes]
//--
//- при определении MATERIALIZED VIEW в селекте из стрима выполняем доп. обработку данных
//- функции: квантиль используем при формировании heatmap-а
//- работа с массами (строки завернуть в массив, получить пересечение, и обратно развернуть в строки, ARRAY JOIN)
//- наши сценарии: формирование аналитики за период
//--

== Модуль Reports
[%step]
* Запросы приходят из Kafka
* Тип запроса -> генератор -> динамический SQL-запрос в Clickhouse
* Форматирование результата (данные, Excel, Pdf)
* Сохранение отчетов в файловое хранилище
* Отправка ответа на запрос в Kafka

//[.notes]
//--
// Обрабатывает аналитические запросов
//--

== Зачем отдельный модуль Reports?
[%step]
* Часть работы выполняется в Java
* Сокрытие работы с Clickhouse за интерфейсом типизированных запросов
* Возможность масштабировать

== Аналитическая панель
[%step]
* Панель виджитов
** своя для каждого пользователя
** виджет периодически отправляет запрос в Reports

== Отчеты
[%step]
* Запрос формирования нового отчета
* Журнал отчетов

== Тепловые карты
(!) картинка

== Маршруты
(!) картинка

== История событий
[%step]
* Вычитывание событий из Kafka
* Сохранение темпа воспроизведения
* Плюсы:
** не нужно отдельное хранилище
** прозрачно для потребителя
** новые типы событий автоматически доступны для истории
* Минусы:
** период хранения истории ограничен
** проблемы с получением состояния в начальный момент времени

//[.notes]
//--
//Специализированный Kafka Consumer, который вычитыва события из топиков
//за заданный период в прошлом с сохранением темпа их поступления.
//--

== Выводы
[%step]
* Kafka - удачный выбор для EDA
* При потоковой обработке помогает кеш
* Clickhouse - тоже удачное решение для накопления аналитических данных

// EDA - Event-driven architecture