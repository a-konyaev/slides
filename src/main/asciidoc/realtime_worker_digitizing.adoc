= Оцифровка рабочего в режиме реального времени
:revealjs_theme: black
:revealjs_customtheme: theme.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images\realtime_worker_digitizing
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900

:!figure-caption:

image::logo.jpg[]

Алексей Коняев
{nbsp} +
ведущий разработчик КРОК
{nbsp} +
akonyaev@croc.ru

== Цифровой рабочий
[cols="30a,70a",frame=none,grid=none]
|===
.^|
* Позиционирование внутри и снаружи помещений
* Выявление внештатных ситуаций
* RealTime аналитика
.^|image::digital_worker.png[]
|===

[.notes]
--
 Бизнес-польза от системы
* быстрое реагирование на внештат. ситуации
* аналитика с целью оптимизации производств. процесса
* в перспективе, это может быть завод с 30тыс сотрудников
--

== Поток обработки событий
image::tag_to_ui.jpg[]

[.notes]
--
 Рассказажу, как данные с носимых устройств превращаются в нотификации в UI.
И как вообще может выглядеть архитектура системы, которая должна справляться
с большим потоком событий и уметь выполнять много разных задач в процессе их обработки.
--

== Архитектура
image::architecture.jpg[width=55%]

[.notes]
--
 На картинке изображены модули, из которых состоит система.
Есть базы данных, файл. хранилище, UI, модули, кот. выполняют взаимодействие с железом и пр.
Но центральное место занимает Кафка.
--

== Kafka
* Событийно-ориентированная архитектура
* Потоковая обработка на Kafka Streams
* Масштабирование обработки
* Взаимодействие модулей внутри системы
* Интеграция с внешними системами

[.notes]
--
 !
* СОА выбрали потому, что на входе у нас события и потом по мере их обработки
    событий рождается еще больше
* потоковая обработка - нужно обрабатывать события на лету, причем
    логика обработки растет, как снежный ком. Но при этом, нужно было сохранить
    независимость кусков логики друг от друга, иметь возможность в будущем
    добавлять новые кейсы обработки событий
* Партиционирование топиков позволяет масштабировать обработку
* взаимодействие модулей и интеграция - это нужно было в любом случае делать,
    и кафка удовлетворяет все наши потребности в этом:
** единая точка определения форматов (на каждое событие есть свой класс + json-сериализация)
** балансировка благодаря партиционированию топиков
** асинхронность (не везде нужно, но там где нельзя "зависать", оч. полезно)
--

== Поток событий

image::flow_1.jpg[width=75%]

== Адаптер
* Около 10 штук на данный момент
* Подключение к вендорским системам с помощью
** REST API
** Kafka
** MQTT
** WebSocket
** SignalR
* Подключение напрямую к оборудованию
* Сложно масшабировать => нужна высокая производительность

[.notes]
--
 !
* "переходники" между внешники системами и нашей
* нужна макс. производительность, поэтому ничего лишнего не делаем
* на входе API внешней системы - на выходе т.н. "сырые" события во внутреннем формате
--

== "Сырые" события
[cols="50a,50a",frame=none]
|===
.^|
* Перемещение - TagMovement
* Телеметрия - TagInfo
* Тревога - TagAlert
.^|
* Внутренний универсальный формат
* до 5 событий в секунда от одной метки
* Долго не храним (1 сутки)
|===

[.notes]
--
 ! Эти события имеет смысл хранить только на время потенциального останова системы из-за сбоя,
т.к. они в нормальной ситуации сразу же обрабатываются, после чего их можно выкинуть.
--

== Поток событий

image::flow_2.jpg[width=75%]

== Транслятор
* Вычисление абсолютных координат
* Связывание метки с объектом
* Определение остановки объекта
* Обнаружение потери сигнала
* Вход/выход из геозоны
* Подсчет объектов в геозоне
* ...

[.notes]
--
 ! Это модуль, который обрабатывает сырые события. Например, он решает такие то задачи:
- в том числе зональное позиционирование - привести пример с координатами за окном.
Результатом работы транслятора являются другие события.
--

== Транслятор. Процессоры

[cols="50a,50a",frame=none]
|===
.^|
* Kafka Streams Processors API
* Stateful-обработка
* Пунктуатор
* Один тип события -- один топик
.^|
image::topology.jpg[]
|===

[.notes]
--
 !
* Почему Kafka Streams?
** изначально выбрав кафку, знали что в ней есть механизм потоковой обработки.
** Есть возможность использовать состояние
** Есть пунктуаторы - позволяют периодически проверять все состояния
** Из одного топика могут параллельно и независимо получать события разные консюмеры
* Сделали обертку над Kafka Streams API, чтобы можно было
на уровне кода оперировать типом события на вход и на выход,
что значительно упрощает добавление нового процессора
--

== Транслятор. Кэширование
[cols="70a,30a",frame=none]
|===
.^|
* Оптимизация доступа к БД
* Hazelcast
** просто библиотека
** распределенный кэш
** проверенное Open Source решение

.^|image::processor.jpg[]
|===

[.notes]
--
 !
* Для чего вообще оптимизация доступа к БД? Все события, которые мы обрабатываем в потоке, важно обрабатывать максимально быстро!
Суммарное время обработки одного сырого события не должно превышать период поступления событий.
Но и нужно учитывать, что события поступают не от одной метки, а от многих.
А постоянно ходить в БД оч. долго, да и не выдержит она.
* просто библиотека - не нужно поднимать отдельного зверя, как например в случае с Redis
* распределенный кеш - распределенная хеш-таблица по всем узлам кластера, то что нужно в нашем случае
партиционирования по ИД объектов.
** но с другой стороны, какие то кэши дублируются на каждой ноде => жрут память
* много кто использует - Тинькофф, Яндекс, нам тоже хотелось попробовать
--

== Транслятор. Производительность

* 1 экземпляр
** 2 CPU + 2 Gb
** Amazon EC2 t4g.micro
* Пропускная способность
** Events per second
*** входящие -- 500 EPS
*** новые -- 1500 EPS
** 100 до 10 тысяч меток
* Объем на диске Kafka:
** входящие -- 36 Gb/day
** новые -- 1 Tb/month

[.notes]
--
 ! t4g instances - это general purpose
 ! для топиков включено сжатие zstd
--

== Бизнес-события
* На одно "сырое" -- несколько бизнес-событий
* Передаются в UI и другим потребителям
* Храним долго (1 месяц)

[.notes]
--
 ! На самом деле, хранить эти события нужно только для задачи воспроизведения истории,
т.е. Кафка не используется как место для хранения результатов работы системы.
Но про то, где и как храним будет дальше.
--

== Поток событий

image::flow_3.jpg[width=75%]

== Перемещение объектов
* UI подписывается на бизнес-события
* Передает события на клиента через веб-сокет
* Фильтрация и редукция потока событий
* Кластеризация объектов

[.notes]
--
 !
* Не предполагается High-load-а для работы с UI, но в то же время гнать на клиента все-все события нельзя,
т.к. их оч. много.
* Фильтрация потока событий в зависимости от текущей выбранной геозоны
** кластеризация на клиенте
--

== Демо
{nbsp}

Перемещение объектов

== Поток событий

image::flow_4.jpg[width=75%]

== Complex Event Processing
[cols="40a,60a",frame=none]
|===
.^|
image::david_luckham.jpg[width=50%]
David Luckham,
{nbsp}

Stanford University
.^|
Обработка потока различных событий в реальном времени
с целью выявления паттернов значимых событий
|===

[.notes]
--
 ! CEP - развивающаяся парадигма, разработанная в 1990-х годах
    доктором Дэвидом Лакхэмом из Стэнфордского университета.
--

== ESP vs CEP
[cols="45a,10a,45a",frame=none]
|===
|
Event Stream Processing

* Один поток упорядоченных событий
* Фильтрация, трансформация
* Агрегация, группировка
|
|
Complex Event Processing

* Различные потоки не обязательно упорядоченных событий
* Причинно-следственная связь
* Анализ событий внутри временного окна
|===
[.notes]
--
 ! Пример ESP - следить на ценой акций и продавать при достижении определенного порога
 ! CEP - развивающаяся парадигма, разработанная в 1990-х годах доктором Дэвидом Лакхэмом из Стэнфордского университета.
 ! Пример ESP - следить на ценой акций и продавать при достижении определенного порога
 ! CEP was developed at Stanford University between 1989 and 1995
 ! задача CEP - выявить определенные шаблоны в потоке низкоуровневых событий, при этом зачастую
комбинируя данные из различных источников, чтобы составить общую картину о мире.
 ! CEP - более сложная штука чем ESP
 ! пришел 1: в крок гость на митап, и проник в тренаж. зал, в который и просто сотрудников крок не пускают,
если не подписал соблюдение правил безопасности.
    ну это просто - вход в зону
 ! пример 2: пошел новый (!) сотрудник в тренажерный зал (вход в зону), встал на бег. догожку и
побежал, при этом пульс у него поднялся выше тревож. уровня (предполагаем, что как то может его определить)
и бежит так долгое время - аларм, вдруг ему плохо станет!
 ! еще пример: средняя скорость всех сотрудников стала выше средней на 50% - алерт! все куда то побежали?

 ! на самом деле CEP - это более ложная версия ESP, или ESP - это подмножество CEP.
* также цель - не спамить в оператора по каждому алерту, а сообщить когда точно есть проблема.
--

== CEP-процессор
* Правила, которые выявляют внештатные ситуации
** вход в опасную зону
** неправильная ориентация каски
** пульс выше/ниже нормы
** удар/падение/неподвижность
* Сложные события регистрируются в журнале
* Отправляются нотификации

== Esper
* 2006 by EsperTech Inc.
* Open Source, Java
* Есть интеграция с Kafka
* Event Processing Language
** Расширение SQL
** Компилируется в байткод
* Горизонтально масштабируемый

[.notes]
--
* зрелый продукт с богатым функционалом, мы его используем далеко не на всю его мощность
* интеграцию с Kafka - пришлось немного допилить, чтобы явно указывать топики,
* из которых читать и топики, в которые писать
--

== Esper. Пример
{nbsp}

[cols="20a,80a",frame=none]
|===
.<| Задача:
.<| Не оставлять включенное оборудование без присмотра
.<| Дано:
.<|
* Событие "Изменение кол-во людей в геозоне"
* Событие "Изменение состояния оборудования"
* Макс. время без присмотра - 1 час
|===

== Esper. EPL. Схемы
[source,sql]
----
create schema PersonsInGym(zoneId string, numberOfPersons int);
create schema TreadmillStatus(zoneId string, deviceId string, turnedOn bool);

insert into PeopleInGym
select
    e.zoneId,
    e.numberOfPersons
from
    ZoneObjectsEvent(zoneId = "Gym") e;

insert into TreadmillStatus
select
    e.zoneId,
    e.deviceId,
    e.turnedOn
from DeviceStatusEvent(type = "Treadmill") e;
----

[.notes]
--
 !
* События из Kafka
** топик -> таблица
** событие -> строка в таблице
* Схема - runtime-таблицы
--

//== Esper. EPL. Окна
//* Последние N событий
//[source,sql]
//----
//select * from Event#length(N)
//----
//* Скользящее (sliding)
//[source,sql]
//----
//select sum(amount) from Event#time(T)
//----
//* Прыгающее (hopping)
//[source,sql]
//----
//select name, avg(amount)
//from Event(amount > 100)#time_batch(T)
//group by name
//----
//
//[.notes]
//--
//* sliding - события за последние T секунд
//* hopping / tumbling - события за последнюю пачку из Т секунд
//--

== Esper. EPL. Контекст
{nbsp}

ВКЛ -> (ВЫКЛ или ("Зал пуст" -> прошел час))
{nbsp}

{nbsp}

[source,sql]
----
create context UnattendedTreadmillCtx
    partition by zoneId, deviceId from TreadmillStatus
    initiated by TreadmillStatus(turnedOn = true)
    terminated by pattern[
        TreadmillStatus(turnedOn = false) or
        (PersonsInGym(numberOfPersons = 0) -> timer:interval(1 hour))
    ];
----

//create context UnattendedTreadmillCtx
//partition by objectId FROM ZoneEntranceEvent
//initiated by ZoneEntranceEvent(entranceType = ENTERED)
//terminated by pattern[ZoneEntranceEvent(entranceType = LEFT) OR timer:interval(60 sec)];

[.notes]
--
 !
* Партиционирование по полям событий
* Условие создания и удаления
* партиция/контекст - таблица, в которой накапливаются события для анализа
* чтобы партиционировать, нужно объявить контект
* или более сложные варианты окон из комбинации событий: [A -> B or C]
--

== Esper. EPL. Выражения
{nbsp}

{nbsp}

[source,sql]
----
@KafkaOutputTopic('notification')
context UnattendedTreadmillCtx
select transpose(createNotification(
    e.zoneId,
    e.deviceId
))
from TreadmillStatus(turnedOn = false)#lastevent e
----

[.notes]
--
* @KafkaOutputTopic - наша аннотация
* transpose - встроенная функция, которая принимает java-объект и отправляет его в выходной поток
* createNotification - наш метод, который задекларирован при инициализации Esper-а
--

== Esper. Плюсы и минусы
[cols="50a,50a",frame=none]
|===
.^|
(*+*) Понятен не только разработчикам
{nbsp}

(*+*) Расширяемый
{nbsp}

(*+*) Мощный инструмент

.^|
(*-*) Сложно освоить инструмент
{nbsp}

(*-*) Сложно отлаживать
|===

[.notes]
--
 ! Для отладки есть Online Notebook
--

== Esper. Альтернатива - Kafka?
image::is_ksqldb_cep.jpg[width=80%]

[.notes]
--
 !
* Kafka Streams - низкоуровневый API на Java
* KSqlDB - все-таки это ESP, а не CEP
--

== Esper. Альтернативы
* FlinkCEP - мало возможностей
* Spark Streaming - аналог Kafka Streams
* TIBCO Streaming - платная
* ...

[.notes]
--
 !
* Flink-CEP, писать на java, нет окон
--

== Поток событий

image::flow_5.jpg[width=75%]

== Демо
{nbsp}

Журнал событий и нотификации
[.notes]
--
 !
Срабатывания предупреждения при внештатной ситуации - вход постороннего в зону работ по НД
--

== Поток событий
image::flow_6.jpg[width=75%]

== Подготовка данных
На Kafka Streams процессорах:

* Фильтрация
* Денормализация / обогащение
* Форматирование
* Фиксирование истории (*)

[.notes]
--
 !
* фильтрация
** для треков: пропускать событие, если объект переместился незначительно
** только события входа и выхода из зоны
* обогащение - достать в событие сразу все необходимые данные, чтобы потом быстрее выполнять запрос
* форматирование - выпремление json-а
--

== Поток событий
image::flow_7.jpg[width=75%]
//image::analytic.jpg[]

== Clickhouse
* Аналитическая БД от Yandex
* Колоночная, Масштабируемая, Отказоустойчивая
* Подходит для Time-series данных
* Хороший вариант использования - читать данные "пачками"

[.notes]
--
 !
* Time-series - упорядочены по времени
* читать данные "пачками" - как раз кейз формирования отчетов за период времени
--

== Clickhouse. Как используем
* Загрузка данных из Kafka
* Дополнительная обработка при загрузке данных
* Подключение справочников из PostgreSql
* Партиционирование данных по времени события и ИД объекта!
* Аналитические функции

[.notes]
--
 !
* встроенный движок загрузки данных из Kafka
* при определении MATERIALIZED VIEW в селекте из стрима выполняем доп. обработку данных
* подключение справочников в виде словарей, которые КХ сам периодически обновляет
аналитическая БД, в которой накапливаем данные
* функции: квантиль используем при формировании heatmap-а
* работа с массами (строки завернуть в массив, получить пересечение, и обратно развернуть в строки, ARRAY JOIN)
* наши сценарии: формирование аналитики за период
--

== Поток событий
image::flow_8.jpg[width=75%]

[.notes]
--
 ! Sling - это CMS, но мы его используем чтобы хранить сформированные отчеты
--

== Формирование отчетов
* Запросы приходят из Kafka
* Тип запроса -> генератор -> динамический SQL-запрос
* Форматирование результата (данные, Excel, Pdf)
* Сохранение отчетов в Sling
* Отправка ответа на запрос в Kafka

== Асинхронные запросы через Kafka
[cols="50a,50a",frame=none]
|===
.^|
(*+*) Не ждем, пока запрос выполняется
{nbsp}

(*+*) Заказать отчет может кто угодно
{nbsp}

(*+*) Масштабирование

.^|
(*-*) "Заказчик" должен сопоставить ответ с запросом
{nbsp}

|===

[.notes]
--
 !
* обычно запрос выполняется быстро, но если задать большой диапазон дат, например, то может и долго.
** кроме того, как обработки приходится делать руками на Java
* масштабируемся и балансируемся благодаря партиционированию топиков в кафке
--

== Аналитическая панель
image::widgets.jpg[]

[.notes]
--
 !
* Общие панели
* Личные панели
* Виджет периодически отправляет запрос
--

== Отчеты
image::reports.jpg[]

[.notes]
--
 !
* Запрос через Kafka
* Нотификация о готовности
* Доступ к отчетам через Sling - Файлы сформированных отчетов складываются по определенным путям в Sling так,
чтобы каждый пользователь мог быстро получить свои ранее заказанные отчеты
--

== Тепловые карты
image::heatmap.jpg[]

== Маршруты
image::route.jpg[]

== История событий
* Вычитывание событий из Kafka за период в прошлом
* Сохранение темпа воспроизведения
* Плюсы
** не нужно отдельное хранилище
** прозрачно для потребителя
** новые типы событий автоматически доступны для истории
* Минусы
** период хранения истории ограничен
** проблемы с получением состояния в начальный момент времени

[.notes]
--
 !
Специализированный Kafka Consumer, который вычитыва события из топиков
за заданный период в прошлом с сохранением темпа их поступления.
--

== Выводы
[%step]
* Kafka - удачный выбор для Event Driven Architecture
* При потоковой обработке помогает кеш
* Esper - хорошее решение для CEP
* Clickhouse - то, что нужно для аналитическии по Time-series данным

[.notes]
--
* вообще на Kafka можно сделать всю интеграцию и балансировку, как внутренюю, так и внешнюю
* кеш - потому что нелья тормозить поток. обработку
* Esper - много всего умеет и в принципе, довольно удобное решение,
но нужно поднатаскаться и изучить возможности
* Clickhouse - партиционирование, масштабируемость, заточен под аналитику
--