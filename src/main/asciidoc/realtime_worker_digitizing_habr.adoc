= Оцифровка рабочего в режиме реального времени
:revealjs_theme: black
:revealjs_customtheme: theme.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images\realtime_worker_digitizing_habr
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900

:!figure-caption:

Привет, Хабр! Я Алексей Коняев, ведущий разработчик в КРОК.

Последние пару лет участвую в проекте "Цифровой рабочий" в роли ведущего java-разработчика.
Если в двух словах, то это система, которая позволяет предотвращать внештатные ситуации на производстве
благодаря определению местоположения людей с помощью носимых устройств Outdoor/Indoor-навигации,
т.е. когда навигация и на улице, и внутри зданий.

Представьте, что вы приехали на экскурсию на завод. Там огромная территория и
вы вместе с гидом передвигаетесь на машине, он рассказывает: "посмотрите направо, здесь новое здание литейного цеха,
а вот слева старое здание, которое скоро должны снести...". Как вдруг через минуту это старое здание взрывают!
Гид, конечно, в шоке, да и вы тоже, но, к счастью, все обошлось:) Спрашивается,
какого черта машина с экскурсантами оказалась в месте проведения взрывных работ?!
И наша система на этот вопрос тоже не ответит, но она поможет вовремя предупредить всех заинтересованных
лиц о том, что в геозоне, где сейчас проводятся опасные работы, появились посторонние.

Еще пример: сотрудник залез на стремянку, чтобы затянуть вентиль газовой трубы.
Резьба вдруг сорвалась, сотрудник не удержался и, упав с высоты 5 метров, от удара потерял сознание.
А вентиль при этом открылся и газ начал поступать в помещение.
Но датчики падения и удара, которые встроны в носимое устройство, передали сигналы на сервер.
Там эти два сигнала были обработаны и алгоритм выявления внештатных ситуаций сформировал
событие-тревогу, которое было передано оператору, а также другим сотрудникам,
которые находятся недалеко от пострадавшего и могут быстро прийти ему на помощь.

Ещё "Цифровой рабочий" позволяет строить различную аналитику, в том числе realtime, а также
выполнять "разбор полетов", т.е. воспроизводить историю событий, чтобы можно было выяснить,
что привело к нежелательной ситуации и постараться избежать ее в будущем.

Как именно все это внутри работает и как мы используем Kafka, Esper и Clickhouse, я расскажу под катом.

image::digital_worker.png[]

== Архитектура
image::architecture_0.jpg[]

Когда мы только начинали проектировать "Цифровой рабочий", то решили пойти по пути
https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D0%B1%D1%8B%D1%82%D0%B8%D0%B9%D0%BD%D0%BE-%D0%BE%D1%80%D0%B8%D0%B5%D0%BD%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D0%B0%D1%8F_%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0[Событийно-ориентированной архитектуры].

Рассуждали мы так: все начинается с носимых устройств, или, как мы их называем "меток".
Эти метки, по сути, просто умеют передавать с определенной частотой какую то телеметрию или, другими словами, информацию
об изменении своего внутреннего состояния. И вот это изменение состояния метки и есть входное для системы событие.
Далее, нам нужно уметь обрабатывать поток этих входных события, причем, это должен быть не просто последовательный конвейер,
а параллельная обработка разными модулями, которые в процессе работы будут порождать новые события,
обрататываемые другими модулями и т.д.
В итоге, какие то события будут передаваться в UI, чтобы отрисовывать перемещение объектов на карте.

В качестве шины или слоя передачи событий мы выбрали https://kafka.apache.org/[Apache Kafka].
На тот момент Kafka уже зарекомендовала себя
как зрелый и надежный продукт (мы начинали с версии 2.0.0). Кроме того, выбирали только среди Open Source решений,
чтобы удовлетворить требованиям импортозамещения. А с функциональной точки зрения, в Kafkа нам понравилась возможность
независимо подключать различных консьюмеров к одному и тому же топику,
возможность прочитать события из топика еще раз за период в прошлом,
механизм стриминговой обработки Kafka Streams, ну и, конечно, масштабируемость благодаря партиционированию топиков.

Архитектура система включает следующие компоненты:

* Есть различные носимые устройства (метки) и системы позиционирования, которые уже существуют на рынке и которые умеют
работать с теми или иными девайсами.
* Для каждой такой системы позиционирования, с которой мы решили интегрироваться, у нас есть свой модуль *Адаптер*, который
публикует в кафку события с телеметрией от меток.
* Далее, эти события обрабатываются *Транслятором*, который выполняет первичную обработку (связывание метки с сотрудником,
вычисление геозоны, в которой находится сейчас метка и др.).
* Модуль Complex Event Processing-а (*CEP-процессор*) обрабатывает события, которые порождает Транслятор;
здесь мы занимаемся выявлением внештатных ситуаций, анализируя различные типы событий, в том числе от разных меток.
* В *UI* поступают собятия как от Транслятора (для отрисовки перемещения сотрудников), так и от CEP-процессора (отображение алертов).
Основную рабочую область UI занимает карта с 3D-моделями зданий, которые можно посмотреть "в разрезе" - провалиться на
любой этаж и увидеть, что там происходит. Для отрисовки 3D-моделей мы используем библиотеку
https://cesium.com/cesiumjs[CesiumJS].
* Для хранения справочных данных, как то список меток, сотрудников, геозон и пр., используем реляционную БД - *PostgreSQL*.
* А для хранения данных, по которым строится аналитика - *ClickHouse*.
* Но в ClickHouse напрямую никто не ходит - для этого используется модуль Reports, который выполняет обработку
запросов к аналитическим данным (запросы на обновление данных виджетов на аналитической панели в UI,
запросы на формирование различных отчетов и др.).
* И еще есть файловое хранилище *S3*, где мы храним файлы 3D-моделей и файлы сформированных отчетов.

Ну а теперь давайте расскажу поподробнее про все модули системы, как они устроены внутри.

== Адаптеры
image::helmet.png[]

 (координаты, а также,
если в метку встроены датчики, то их значения, например, температура, давление, уровень CO2, заряд аккумулятора и пр.).

* говорю, о том, что КРОК ведь интегратор, поэтому мы интегрируем разные другие вендорские системы,
    которые уже умеют взаимодействовать с различными метками
* адаптеры - это такие посредники, которые подключаются к вендорским системам
* но есть адаптеры, которые сами напрямую взаимодействуют с оборудованием.
* привести примеры, в том числе где мы сами реализуем все без вендора, в том числе определение координат
с помощью трилатерации

* про сложности масштабирования адаптеров и как следствие стремление сделать адаптер максимально
простым и производительным
* результат работы адаптеров - т.н. "сырые события":
** это наш универсальный формат
** храним в кафке с таким то ретеншеном

== Транслятор
image::topology.jpg[]

* выполняет обработку сырых событий с целью:
** вычисление географических координат
** определение остановки объекта
** обнаружение потери сигнала
** работа с геозонами
*** вход/выход
*** подсчет объетов в геозоне
* результат работы транслятора - т.н. "бизнес-события"
* обработку "сырых событий" выполняем с помощью Kafka Streams Processor API
** Statefull-обработка
** использование пунктуаторов
** наш подход: один топик - один тип события
** автоматическая сборка топологии из процессоров (с помощью Spring-а)

=== Использование кеширования при потоковой обработке

image::translator_architecture.jpg[]
* проблема производительности транслятора
* решили ее с помощью кеширования обращений к БД
* выбрали Hazelcast
** про его особенности - распределенный кеш и все такое
** про подводные камни - нужно управлять кешами, чтобы они не реплицировались на другие ноды,
    где они не нужны.
* результаты оптимизации (после добавления кеша)

== Отображение объектов на карте
video::demo-1.mp4[]

* немного про архитектуру UI (бекенд + фронтенд)
* UI подписывается на топики кафки с бизнес-событиями
* на клиента данные передаются через веб-сокеты
** при этом выполняем редукцию и фильтрацию потока событий
* клиент - приложение на React-е, а 3D-картинку рисуем с помощью cesium.com

== Complex Event Processing

image::cep.png[]
* Теория - что такое CEP
** про David Luckham
** небольшое сравнение ESP (Event Stream Processing) и CEP-а

=== CEP-процессор

* задачи cep-процессора - какие внештатн. ситуации отслеживает
* результат - регистрация событий в журнале + нотификации
* сделан на базе Esper-а
** немного про сам Esper
* почему все таки Esper, а не тот же Kafka Streams или KSqlDB

=== Пример реализации правила на Esper-е

* описание задачи
* описание решения (куски кода)
* Esper Notebook где можно этот пример проверить и поиграться с Esper-ом

=== Нотификации

* это отдельный модуль, который занимается маршрутизацией нотификаций
** на почту, в телеграм, на метку и конечно в UI, чтобы оператору показать
* это тоже Kafka Streams приложение

== Аналитика

* есть реалтайм, есть формирование отчетов за период
* архитектура: подготовка данных - складывание из в аналитич. БД - запросы к БД через модуль отчетов...
* как это выглядит в UI - ниже картинки

image::analitics_dashboard.png[]
Аналитическа доска с разными виджетами

image::analitics_route.png[]
Маршрут передвижения за период

image::analitics_heatmap.png[]
Heatmap - показывает где больше времени провел сотрудник

=== Модуль подготовки данных

* задачи модуля
* результат - данные в аналитической БД

=== ClickHouse
image::clickhouse.png[]
* какие были требования к аналитической БД
* почему выбрали ClickHouse
* как используем ClickHouse:
** загрузка напрямую из Kafka
** подключение справочников из PostgreSql
** аналитические функции

=== Формирование отчетов

* запросы через кафку
* выполнения запросов к ClickHouse-у
* обработка и форматирование результата
* сохранение результата в S3 (если нужно)
* отправка ответа на запрос тоже через Kafka
** немного про то, почему именно через Kafka

== Воспроизведение истории

* Вычитывание событий из Kafka за период в прошлом
* UI - плеер с возможностью указать период и изменять скорость воспроизведения
* Сохранение темпа воспроизведения
* Плюсы и минусы использования кафки для этой задачи


=== Поток обработки событий

image::flow.jpg[]
* далее буду рассказывать про модули, которые участвуют в обработки событий, начиная от устройств и заканчивая UI


== А что у вас?

На этом буду закругляться. Надеюсь, вам было интересно узнать о том,
как устроен внутри продукт "Цифровой рабочий", который мы разрабатываем в КРОКе.
Но "Цифровой рабочий", на самом деле, только начинает делать первые шаги на своем пути, и активно развивается.
Мы посточнно допиливаем новые фичи, подключаем новые вендорские системы, что-то мы переделываем и оптимизируем.
Иногда экспериментируем с другими технологиями потоковой обработки, но не вместо Kafka, она вне конкуренции:)
Подумываем о том, чтобы прикрутить Machine Learning. В общем, куча идей и планов на будущее!
Было бы интересно услышать в комментариях, разрабатываете ли вы что-то подобное, например,
в области IoT с потоковой обработкой данных, и какие технологии применяете и как.
