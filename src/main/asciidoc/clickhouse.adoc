= ClickHouse
:revealjs_theme: black
:revealjs_customtheme: theme.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images\clickhouse
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900

:!figure-caption:

image::logo.png[]

Алексей Коняев, akonyaev@gmail.ru

== 1. Что такое ClickHouse

* Аналитическая БД
* Колоночная БД
* Масштабируемая и отказоустойчивая

=== Online Analytical Processing (OLAP)

Специфика

* Большинство запросов - на чтение, причем сразу достаточно большого набора данных
* Не требуется изменять ранее записанные данные
* Не нужны транзакции, низкие требования к консистентности данных,

Для чего применяют

* Формирование различных графиков и отчетов, в том числе real-time
* Исследовательская работа на основе накопленных данных

=== Колоночная БД

[source,sql]
----
SELECT * FROM table WHERE color = 542
----

=== Выполнение запроса в строковой БД

image::row_db.png[]


=== Выполнение запроса в колоночной БД

image::column_db.png[]

=== ClickHouse Killer Features

* Хорошо работает с очень широкими таблицами с огромным кол-вом строк
* Быстрая вставка большого потока входных данных
* Интерактивные запросы - в тот же момент, пока идет обработка потока входных данных
* Очень хорошо можно оптимизировать запросы
* Богатый набор типов данных и аналитических функций, в том числе поддержка ML (CatBoost)
* Сжатие данных
* Работа на обычном оборудовании
* Распределенная обработка запросов на всех серверах

=== Сценарии использования

* Time-serias - когда события упорядочены по времени (cбор метрик - вместо Prometheus)
* Стриминг данных из других источников - например, из Kafka
* Хранение логов - как замена Elasticsearch


//*************************************************************************
== 2. Как работает внутри

=== Партиции

* Данные делятся на партиции, которые хранятся независимо
* Партиционирование выполняется по первичному ключу c колонкой типа Data

=== Вставка данных (Insert)

* Вставка сразу на диск без буфера в памяти
** Каждая вставка - новый файл
** Важно делать вставку батчами
* Запись выполняется кусками (part)
** Данные в кусоке записываются в отсортированном виде
** У кусок данных вычисляется хеш, чтобы избежать повторной вставки такого же куска
** Потом в фоне выполняет слияние новых и старых кусков
** (!) Важно следить за метрикой "кол-во кусков в партиции"
* Каждая файл содержит данные из одной колонки
* Файл колонки сжимается указанным для нее кодеком
** Для разных типов данных подходят разные типы кодеков и архиваторов

=== Слияние (Merge)

* Основные движки таблиц - это семейство MergeTree
* Постоянно в фоне сливаются маленькие куски в куски побольше
** процесс не детерминированный
** можно принудительно запустить (команда OPTIMIZE)
* Есть "Пропускная способность" - если КХ не успевает мерджить новые куски,
то при очередной вставке бросит исключение "Too many parts"
* Пропускная способность = Кол-во серверов / (Кол-во таблиц * частота вставок)

=== Материализованное представление (MaterializedView)

* Это триггер на вставку в таблицу-источник
* Работает как функция от блока данных, который вставляется в таблицу-источник
** Если в MV есть агрегативные функции, то они будут применяться только к этому блоку данных, не ко всей таблице
* Результат вставляется в выходную таблицу
* Если есть несколько MV, которые смотрят на одну таблицу-источник, то они будут обрабатывать вставляемый блок последовательно
** Есть настройка parallel_view_processing, которую можно выставить = true

=== Индексы

* Кластерный или первичный ключ
** Может быть только один на таблицу
** Не обеспечивает уникальность
* Разреженный (index_granularity) - одна "засечка" на 8192 строки
* Оптимизирован под запросы, которые выбирают сразу много строк
** плохо работает, если делаем выборку небольшого кол-ва строк (Key-value запросы - плохой вариант)

=== Выборка данных (Select)

* Берет первичный/кластерный ключ и по нему находит сразу все подходящие партиции
* Берет всю партицию и выбирает все подходящие блоки, ориентируясь на разреженный индекс
* Читает блоки, разжимает их и потом уже выполняет дальнейший поиск
* Есть JOIN-ы, но с ограничением
** правая таблица вся должна помещаться в память
** таблицы должны быть расположены на одном сервере (Data locality)

=== Удаление данных (Delete)

* Не умеет удалять как обычная БД
** Оператор Delete - в планах на разработку
* Можно удалить всю партициюи и записать ее заново
** alter table drop partition - синхронный вызов
* Можно затереть колонку дефолтными значениями
** alter table clear column col1 in partition '2020-01-01'
* Можно задать TTL при объявлении таблицы
** Cтарые данные можно перекладывать на медленные диски
* Движок таблиц CollapsingMergeTree
** пишем сразу 2 строки "удали старую, добавь новую" и потом в фоне строки будут схлопываться в одну


//*************************************************************************

== 3. Движки таблиц

=== MergeTree

* Наиболее функциональные движки таблиц ClickHouse
* Именно они и выполняют в фоне слияния кусков данных
* В ключе партиционирования должно быть выражение с типом Date.
* Ключ сортировки - определяет то, какие колонки будут сортироваться
* Ключ семплирования - используется, когда хочется выполнить запрос не по всем данным, а по 1%, например

=== Семейство MergeTree

* AggregatingMergeTree - при слиянии выполняет агрегацию
* CollapsingMergeTree - схлопывает строки, используется для удаления строк
* ReplacingMergeTree - для дедупикации строк с одинаковым значением первичного ключа
* SummingMergeTree - схлопывает строки, выполняе суммирование
* GraphiteMergeTree - для использования в связке с Graphite

=== Dictionary

* Позволяет подключить таблицу во внешней БД
* Конфигурация описываниется в xml-конфиге
* Кешируются в оперативке (если не влезают, то частично)
* Периодически кеш обновляется
* Использование словарей - это своего рода join с внешней таблицей

[source,sql]
----
CREATE TABLE IF NOT EXISTS whswd.dict_person
(
    id          String,
    appointment String,
    department  String
)
ENGINE = Dictionary(person);

select * from dict_person;

dictGetOrDefault('person', 'appointment', id, 'default');
----

=== Специальные движки

* Buffer - накапливает в памяти и периодически сбрасывает в выходную таблицу
* Memory - хранит в памяти в несжатом виде
* Merge - позволяет читать данные одновременно из разных таблиц с одинаковой структурой
* TinyLog - для предварительной обработки


== 4. Как НЕ нужно использовать

=== а)
* Записывать в колонки много данных (блобы, массивы, строки - все, что больше 1 Kb)
** (!) сделать много маленьких колонок с точным типом данных и стараться избегать тип Float
** (!) использовать тип Array
** (!) хранить во вне, а в ClickHouse - ссылки
** (!) резать на куски

=== б)
* Выполнять часто мелкие вставки
** если писать часто и по малу, то ClickHouse может не успевать обрабатывать данные и тогда будет кидать исключения
** помним, что каждый столбец - это 1 файл, поэтому для вставки 1 строки, содержащей N столбцов,
необходимо открыть и записать N файлов
** (!) Использовать буферизацию: Kafka-движок, Buffer-движок и др.

=== в)
* Использовать вычисляемые выражения при определении инсерта,
** будет запускаться на каждую строку
** лучше делать в бекграунде путем подготовки данных в MaterializedView

=== г)
* Использовать строковые типы колонок, когда можно их заменить на числовые
** (!) если строки - значения из справочника, то можно использовать ID, Enum (встроенный тип) или получать хеш от строки
** (!) короткие строки до ~10 символов - ОК
** (!) Если все таки надо хранить строки и они все сильно разные, то ОК, лучше хранить как есть

=== д)
* Создавать много маленьких таблиц
** (!) лучше одна большая мегатаблица с триллионом строк и тысяцами колонок

=== е)
* Выполнять предагрегации - данные будут негибкие, с ними потом уже сложно сделать другие агрегации
** (!) ClickHouse заточен под неагрегированные данные, предагрегировать можно, но слегка

=== ж)
* Добавлять много колонок в первичный ключ
** Ключ нельзя изменить!
** (!) При проектировании схем таблиц важно понимать, какие запросы потом к ней будут выполняться

=== з)
* Много маленьких селектов
** КХ читает с диска пачками и сразу чуть больше, чем надо
** (!) Можно много (миллионы) данных передать в секцию IN

=== и)
* Нормализовывать данные и потом их JOIN-нить
** (!) хранить данные в денормализованном виде, но не забывать про консистентность

=== к)
* Использовать ClickHouse как реляционную БД или Key-Value хранилище

//*************************************************************************
== 4. Язык запросов SQL

=== SQL. Типы данных

* Все привычные примитивные типы
* Array(T)
* Tuple(T1, T2, …)
* Nested(Name1 Type1, Name2 Type2, …)
* Nullable(TypeName)

=== SQL. Выражения

[source,sql]
----
[WITH expr_list|(subquery)]
SELECT [DISTINCT] expr_list
[FROM [db.]table | (subquery) | table_function] [FINAL]
[SAMPLE sample_coeff]
[ARRAY JOIN ...]
[GLOBAL] [ANY|ALL] [INNER|LEFT|RIGHT|FULL|CROSS] [OUTER] JOIN (subquery)|table USING columns_list
[PREWHERE expr]
[WHERE expr]
[GROUP BY expr_list] [WITH TOTALS]
[HAVING expr]
[ORDER BY expr_list]
[LIMIT [offset_value, ]n BY columns]
[LIMIT [n, ]m]
[UNION ALL ...]
[INTO OUTFILE filename]
[FORMAT format]
----

=== SQL. Функции

* Агрегатные функции - min, max, sum, avg, quantile,
* Комбинаторы агрегатных функций - суффикс, который меняет поведение функции
** -If - sumIf(column, condition) - суммирует, если выполняется условие
** -Array - sumArray(arr) - просуммировать все элементы всех массивов arr
* Арифметические, Битовые, Математические, Для работы с Json, IP, URL, Гео-координатами, Строками, Массивами и т.д.

=== SQL. Особенности

* Нет оптимизатора плана выполнения
* Нет визуализатора плана выполнения, но можно заглянуть в логи "system query logs" (SET log_queries = 1)
* PREWHERE - лучше работает для фильтрации по неиндексированным полям
** можно выставить параметр SET optimize_move_to_prewhere = 1
* LEFT ASOF JOIN - склеить два временных ряда, если у них разные временные засечки
* Техника вложенных запросов с массивами - свернули строки в массив, что-то сделали с массивом, развернули массив
* Найти все функции (в документации всего нет): select * from system.functions

//*************************************************************************
== 5. Примеры

=== Читаем из Kafka. Stream

[source,sql]
----
-- Message format example
-- {
--   "id": "95cbe37d-23da-4f1b-bfc4-304820c3e528",
--   "occurred": "2019-06-03T13:34:03.257",
--   "sourceSystemId": "Translator",
--   "zoneId": "1a0938b0-2589-11e9-afa2-a3cc6244bbb0",
--   "objectIdList": ["17"],
--   "timeStamp": 1559558043257
-- }
CREATE TABLE IF NOT EXISTS zone_objects_stream
(
    id             String,
    occurred       String,
    sourceSystemId String,
    zoneId         String,
    objectIdList   Array(String),
    timeStamp      UInt64
)
    ENGINE = Kafka()
        SETTINGS
            kafka_broker_list = 'kafka:9092',
            kafka_topic_list = 'zone-objects',
            kafka_group_name = 'clickhouse',
            kafka_format = 'JSONEachRow'
;
----

=== Читаем из Kafka. Consumer

[source,sql]
----

CREATE TABLE IF NOT EXISTS zone_objects
(
    id             String,
    occurred       DateTime,
    sourceSystemId String,
    zoneId         String,
    objectIdList   Array(String),
    objectsCount   UInt64,
    timeStamp      UInt64
)
    ENGINE = MergeTree()
        PARTITION BY toYYYYMMDD(occurred)
        ORDER BY (occurred, zoneId)
;

CREATE MATERIALIZED VIEW IF NOT EXISTS zone_objects_consumer TO zone_objects
AS
SELECT id,
       parseDateTimeBestEffort(occurred) as occurred,
       sourceSystemId,
       zoneId,
       objectIdList,
       length(objectIdList) as objectsCount,
       timeStamp
FROM zone_objects_stream;
----

=== Быстрое получение последнего значения

system.parts - содержит информацию о кусках данных таблиц семейства MergeTree.

[source,sql]
----
SELECT
    max(max_time) occurred,
    tupleElement(CAST(partition, 'Tuple(UInt8, String)'), 2) objectId
FROM system.parts
WHERE table = 'object_connection_status' AND database = 'my_db'
group by objectId
----

== Масштабирование
* ставим несколько нод (шарды)
** все ноды равноправные и одинаковые, но он использует зукипер тоже)
* есть distributed_table - прокси, которая сама обращается в local_table - которые уже живут на шардах
* шарды выполняют запрос максимально локально (агрегация, хотя бы частичная) - чтобы меньше гонять данные по сети
* чем больше шард, тем выше параллелизм обработки запроса и соотв. тем он быстрее
* при инсерте используется ключ-шардирования... TODO: копнуть грубже

== Отказоустойчивость
* таблицы могут быть реплицируемые и не реплицируемые
* нужен zookeeper, если хотим поднимать реплики
* консистентность - не сразу, но можно выставлять настройки - например "читать только консистентное".
* distributed_table при выполнении запроса сама определяет, в какую реплику с локальнйо таблицей пойти
(может выбирать ту, у которой отстование минимальное)


== Benchmarks

* утверждается, что ClickHouse быстрее многих специализированных аналогов
* по бенчам выигрывает у других популярных timeserias (InfluxDB и TimescaleDB)
* Ссылки
** https://www.altinity.com/benchmarks
** https://www.altinity.com/blog/clickhouse-for-time-series

== Как поднять и выполнять запросы

* докер
* docker exec -it clickhouse clickhouse-client
* из IDEA

== Как программно выполнять запросы

* рест-апи драйвер по http
* есть бинарный нативный интерфейс (внутренний) еще более производительный и драйверы к нему

== Что еще интересного

* 67 в рейтинге - https://db-engines.com/en/system/ClickHouse
* flyway - есть поддержка в PullRequest-е

== Ссылки
* Документация: https://clickhouse.tech
* Репозиторий исходников: https://github.com/ClickHouse/ClickHouse
* Просмотр и поиск по исходникам без IDE: https://clickhouse.tech/codebrowser/html_report/index.html
* Архив презентаций: https://github.com/ClickHouse/clickhouse-presentations
* Понравившиеся мне презентации:
** https://www.youtube.com/watch?v=Ac2C2G2g8Cg
** https://www.youtube.com/watch?v=k5rw8YPTdRo
** https://www.youtube.com/watch?v=efRryvtKlq0
* Вендор: https://www.altinity.com
* Телеграм-канал: https://t.me/clickhouse_ru
